{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from facenet_pytorch import fixed_image_standardization\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import get_loader, read_dataset, CompositeDataset\n",
    "from model import FaceRecognitionCNN\n",
    "from utils import write_json, copy_file, count_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder2DTransformer(nn.Module):\n",
    "    def __init__(self, face_recognition_cnn_path=None):\n",
    "        super(Encoder2DTransformer, self).__init__()\n",
    "\n",
    "        face_cnn = FaceRecognitionCNN()\n",
    "        \n",
    "        if face_recognition_cnn_path is not None:\n",
    "            face_cnn = nn.DataParallel(face_cnn)\n",
    "            state_dict = torch.load(face_recognition_cnn_path, map_location='cpu')\n",
    "            face_cnn.load_state_dict(state_dict)\n",
    "\n",
    "        if face_recognition_cnn_path:\n",
    "            self.encoder2d = nn.Sequential(*list(face_cnn.module.resnet.children()))[:-4]\n",
    "        else:\n",
    "            self.encoder2d = nn.Sequential(*list(face_cnn.resnet.children()))[:-4]\n",
    "        #self.disc1 = nn.Sequential(*list(face_cnn.resnet.children()))[-4:]\n",
    "        #self.disc2 = face_cnn.relu\n",
    "        #self.disc3 = face_cnn.dropout\n",
    "        #self.disc4 = face_cnn.fc\n",
    "        #self.disc = nn.Sequential(*[disc1, disc2, disc3, disc4])\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=1792, nhead=4)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=4)\n",
    "        self.fc = nn.Linear(1792, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        batch_size, num_channels, depth, height, width = images.shape\n",
    "        images = images.permute(0, 2, 1, 3, 4)\n",
    "        images = images.reshape(batch_size * depth, num_channels, height, width)\n",
    "        out = self.encoder2d(images)\n",
    "#         side = out.squeeze(3)\n",
    "#         side = side.squeeze(2)\n",
    "#         side = self.disc1(side)\n",
    "#         side = self.disc2(side)\n",
    "#         side = self.disc3(side)\n",
    "#         side = self.disc4(side)\n",
    "        out = out.reshape(batch_size, depth, 1792, 1, 1)\n",
    "        out = out.squeeze(4)\n",
    "        out = out.squeeze(3)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.transformer_encoder(out)\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = out.index_select(1, torch.tensor([0]).to(device))\n",
    "        out = out.squeeze()\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        np.float32,\n",
    "        transforms.ToTensor(),\n",
    "        fixed_image_standardization\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepfakes_faces_c23', 'original_faces_c23', 'face2face_faces_c23', 'neural_textures_faces_c23', 'faceswap_faces_c23']\n",
      "Using training data: \n",
      "deepfakes_faces_c23\n",
      "face2face_faces_c23\n",
      "faceswap_faces_c23\n",
      "neural_textures_faces_c23\n",
      "original_faces_c23\n"
     ]
    }
   ],
   "source": [
    "datasets = read_dataset(\n",
    "    '../dataset/mtcnn/', transform=transform,\n",
    "    max_images_per_video=10, max_videos=1000,\n",
    "    window_size=11, splits_path='../dataset/splits/'\n",
    ")\n",
    "# only neural textures c40 and original c40\n",
    "datasets = {\n",
    "    k: v for k, v in datasets.items() \n",
    "    if ('original' in k or 'neural' in k or 'face2face' in k or 'faceswap' in k or 'deepfakes' in k) and 'c23' in k\n",
    "}\n",
    "print('Using training data: ')\n",
    "print('\\n'.join(sorted(datasets.keys())))\n",
    "\n",
    "trains, vals, tests = [], [], []\n",
    "for data_dir_name, dataset in datasets.items():\n",
    "    train, val, test = dataset\n",
    "    # repeat original data multiple times to balance out training data\n",
    "    compression = data_dir_name.split('_')[-1]\n",
    "    num_tampered_with_same_compression = len({x for x in datasets.keys() if compression in x}) - 1\n",
    "    count = 1 if 'original' not in data_dir_name else num_tampered_with_same_compression\n",
    "    for _ in range(count):\n",
    "        trains.append(train)\n",
    "    vals.append(val)\n",
    "    tests.append(test)\n",
    "    \n",
    "train_dataset, val_dataset, test_dataset = CompositeDataset(*trains), CompositeDataset(*vals), CompositeDataset(*tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 57560, validation data size: 6975\n"
     ]
    }
   ],
   "source": [
    "tqdm.write('train data size: {}, validation data size: {}'.format(len(train_dataset), len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(\n",
    "    train_dataset, 64, shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = get_loader(\n",
    "    val_dataset, 64, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[device(type='cuda')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('training on', device)\n",
    "[device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Encoder2DTransformer(\n",
       "    (encoder2d): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): BasicConv2d(\n",
       "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): BasicConv2d(\n",
       "        (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block35(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (branch2): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (8): Mixed_6a(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (9): Sequential(\n",
       "        (0): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (5): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (6): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (7): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (8): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (9): Block17(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (10): Mixed_7a(\n",
       "        (branch0): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (11): Sequential(\n",
       "        (0): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (3): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (4): Block8(\n",
       "          (branch0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (branch1): Sequential(\n",
       "            (0): BasicConv2d(\n",
       "              (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (1): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "            (2): BasicConv2d(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (12): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (13): AdaptiveAvgPool2d(output_size=1)\n",
       "    )\n",
       "    (encoder_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "      (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=1792, out_features=1792, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1792, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1792, bias=True)\n",
       "          (norm1): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1792,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=1792, out_features=5, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder2DTransformer('./model/facenet/model.pt')\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "#if args.freeze_first_epoch:\n",
    "#for m in model.resnet.parameters():\n",
    "#    m.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape torch.Size([64, 3, 11, 160, 160])\n",
      "model params (trainable, total): (123589381, 123589381)\n"
     ]
    }
   ],
   "source": [
    "input_shape = next(iter(train_loader))[2].shape\n",
    "print('input shape', input_shape)\n",
    "# need to call this before summary!!!\n",
    "model.eval()\n",
    "# summary(model, input_shape[1:], batch_size=input_shape[0], device=device)\n",
    "print('model params (trainable, total):', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-5, weight_decay=1e-3\n",
    ")\n",
    "\n",
    "# decrease learning rate if validation accuracy has not increased\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=1/4, patience=2, verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(epoch, model, val_acc):\n",
    "    \n",
    "    model_dir = os.path.join('./model', 'enctrf')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(model_dir, f'model.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    model_info = {\n",
    "        'epoch': epoch,\n",
    "        'val_acc': val_acc[0],\n",
    "        'model_str': str(model)\n",
    "    }\n",
    "    json_path = os.path.join(model_dir, 'info.json')\n",
    "    write_json(model_info, json_path)\n",
    "\n",
    "    #src_model_file = os.path.join('facenet', 'model.py')\n",
    "    #dest_model_file = os.path.join(model_dir, 'model.py')\n",
    "    #copy_file(src_model_file, dest_model_file)\n",
    "\n",
    "    tqdm.write(f'New checkpoint saved at {model_path}')\n",
    "\n",
    "\n",
    "def print_training_info(batch_accuracy, loss, step):\n",
    "    log_info = 'Training - Loss: {:.4f}, Accuracy: {:.4f}'.format(loss.item(), batch_accuracy)\n",
    "    tqdm.write(log_info)\n",
    "\n",
    "    #writer.add_scalar('training loss', loss.item(), step)\n",
    "    #writer.add_scalar('training acc', batch_accuracy, step)\n",
    "\n",
    "\n",
    "def print_validation_info(criterion, device, model, val_loader, epoch, step):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_values = []\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        targets = []\n",
    "        outputs = []\n",
    "        for video_ids, frame_ids, images, target in val_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "            target = target.long()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            loss_values.append(loss.item())\n",
    "            targets.append(target)\n",
    "            outputs.append(output)\n",
    "            #predictions = outputs > 0.0\n",
    "            #all_predictions.append(predictions)\n",
    "            #all_targets.append(targets)\n",
    "            #if args.debug:\n",
    "            #    tqdm.write(outputs)\n",
    "            #    tqdm.write(predictions)\n",
    "            #    tqdm.write(targets)\n",
    "        \n",
    "        val_loss = sum(loss_values) / len(loss_values)\n",
    "        \n",
    "        outputs = torch.cat(outputs, 0)\n",
    "        targets = torch.cat(targets, 0)\n",
    "        \n",
    "        val_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "        \n",
    "        total_target = targets.unique(return_counts=True)[1]\n",
    "        pristine = ((outputs.argmax(1) == 0) * (targets == 0)).sum() / total_target[0]\n",
    "        face2face = ((outputs.argmax(1) == 1) * (targets == 1)).sum() / total_target[1]\n",
    "        faceswap = ((outputs.argmax(1) == 2) * (targets == 2)).sum() / total_target[2]\n",
    "        neural = ((outputs.argmax(1) == 3) * (targets == 3)).sum() / total_target[3]\n",
    "        deepfake = ((outputs.argmax(1) == 4) * (targets == 4)).sum() / total_target[4]\n",
    "        \n",
    "        tqdm.write(\n",
    "            'Validation - Loss: {:.3f}, Acc: {:.3f}, Pr: {:.3f}, Ff: {:.3f}, Fs: {:.3f}, Nt: {:.3f}, Df: {:.3f}'.format(\n",
    "                val_loss, val_accuracy, pristine, face2face, faceswap, neural, deepfake\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return val_accuracy, pristine, face2face, faceswap, neural, deepfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  33%|      | 299/899 [07:35<08:43,  1.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0130, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  33%|      | 299/899 [09:57<08:43,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.793, Acc: 0.826, Pr: 0.571, Ff: 0.897, Fs: 0.961, Nt: 0.760, Df: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  33%|      | 300/899 [10:05<7:38:44, 45.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  67%|   | 599/899 [13:58<04:04,  1.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0050, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  67%|   | 599/899 [15:24<04:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.730, Acc: 0.841, Pr: 0.682, Ff: 0.904, Fs: 0.893, Nt: 0.804, Df: 0.922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0:  67%|   | 600/899 [15:30<2:22:40, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 0: 100%|| 899/899 [19:21<00:00,  1.29s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.844, Acc: 0.822, Pr: 0.650, Ff: 0.790, Fs: 0.967, Nt: 0.811, Df: 0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  33%|      | 299/899 [04:01<07:43,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0183, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  33%|      | 299/899 [05:30<07:43,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.784, Acc: 0.848, Pr: 0.635, Ff: 0.912, Fs: 0.945, Nt: 0.796, Df: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  33%|      | 300/899 [05:37<4:57:00, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New checkpoint saved at ./model/enctrf/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  67%|   | 599/899 [09:34<03:58,  1.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0096, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1:  67%|   | 600/899 [11:02<2:15:16, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.734, Acc: 0.831, Pr: 0.642, Ff: 0.903, Fs: 0.841, Nt: 0.842, Df: 0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 1: 100%|| 899/899 [14:58<00:00,  1.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.792, Acc: 0.835, Pr: 0.666, Ff: 0.905, Fs: 0.966, Nt: 0.667, Df: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  33%|      | 299/899 [03:51<08:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0009, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  33%|      | 300/899 [05:20<4:34:10, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.810, Acc: 0.845, Pr: 0.616, Ff: 0.860, Fs: 0.968, Nt: 0.857, Df: 0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  67%|   | 599/899 [09:07<03:45,  1.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0013, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2:  67%|   | 600/899 [10:34<2:13:19, 26.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.752, Acc: 0.839, Pr: 0.731, Ff: 0.874, Fs: 0.991, Nt: 0.744, Df: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch 2: 100%|| 899/899 [14:20<00:00,  1.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.623, Acc: 0.859, Pr: 0.726, Ff: 0.849, Fs: 0.960, Nt: 0.806, Df: 0.952\n",
      "New checkpoint saved at ./model/enctrf/model.pt\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "step = 1\n",
    "best_val_acc = 0.5\n",
    "for epoch in range(3):\n",
    "    for i, (video_ids, frame_ids, images, targets) in \\\n",
    "            tqdm(enumerate(train_loader), desc=f'training epoch {epoch}', total=len(train_loader)):\n",
    "        model.train()\n",
    "        # Set mini-batch dataset\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward, backward and optimize\n",
    "        outputs = model(images)\n",
    "        targets = targets.long()\n",
    "        loss = criterion(outputs, targets)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Print log info\n",
    "        step += 1\n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            print_training_info(batch_accuracy, loss, step)\n",
    "\n",
    "        if (i + 1) % 300 == 0:\n",
    "            val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc = print_validation_info(\n",
    "                criterion, device, model, val_loader, epoch, step\n",
    "            )\n",
    "            if val_acc > best_val_acc:\n",
    "                save_model_checkpoint(epoch, model, (val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc))\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "    # validation step after full epoch\n",
    "    val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc = print_validation_info(\n",
    "        criterion, device, model, val_loader, epoch, step\n",
    "    )\n",
    "    lr_scheduler.step(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        save_model_checkpoint(epoch, model, (val_acc, pr_acc, ff_acc, fs_acc, nt_acc, df_acc))\n",
    "        best_val_acc = val_acc\n",
    "\n",
    "#    if epoch == 0:\n",
    "#        for m in model.resnet.parameters():\n",
    "#            m.requires_grad_(True)\n",
    "#        tqdm.write('Fine tuning on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 218/218 [02:16<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 1.192, Acc: 0.770, Pr: 0.819, Ff: 0.725, Fs: 0.791, Nt: 0.608, Df: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Encoder2DTransformer()\n",
    "model = nn.DataParallel(model)\n",
    "state_dict = torch.load('./model/enctrf/model.pt', map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "test_loader = get_loader(\n",
    "    test_dataset, 32, shuffle=True, num_workers=2, drop_last=False\n",
    ")\n",
    "with torch.no_grad():\n",
    "    loss_values = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for video_ids, frame_ids, images, target in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        target = target.long()\n",
    "        output = model(images)\n",
    "        targets.append(target)\n",
    "        outputs.append(output)\n",
    "        loss = criterion(output, target)\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "#                 predictions = outputs > 0.0\n",
    "#                 all_predictions.append(predictions)\n",
    "#                 all_targets.append(targets)\n",
    "\n",
    "    val_loss = sum(loss_values) / len(loss_values)\n",
    "\n",
    "    outputs = torch.cat(outputs, 0)\n",
    "    targets = torch.cat(targets, 0)\n",
    "        \n",
    "    val_accuracy = float((outputs.argmax(1)).eq(targets).sum()) / len(targets)\n",
    "\n",
    "    total_target = targets.unique(return_counts=True)[1]\n",
    "    pristine = ((outputs.argmax(1) == 0) * (targets == 0)).sum() / total_target[0]\n",
    "    face2face = ((outputs.argmax(1) == 1) * (targets == 1)).sum() / total_target[1]\n",
    "    faceswap = ((outputs.argmax(1) == 2) * (targets == 2)).sum() / total_target[2]\n",
    "    neural = ((outputs.argmax(1) == 3) * (targets == 3)).sum() / total_target[3]\n",
    "    deepfake = ((outputs.argmax(1) == 4) * (targets == 4)).sum() / total_target[4]\n",
    "    tqdm.write(\n",
    "        'Test - Loss: {:.3f}, Acc: {:.3f}, Pr: {:.3f}, Ff: {:.3f}, Fs: {:.3f}, Nt: {:.3f}, Df: {:.3f}'.format(\n",
    "            val_loss, val_accuracy, pristine, face2face, faceswap, neural, deepfake\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
